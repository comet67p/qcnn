{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-3\n",
    "QUBITS = 166\n",
    "NEURONS_FROM = 0\n",
    "NEURONS_PREDICTED = 166\n",
    "EPOCHS = 4\n",
    "MODE = \"Train\"\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_algorithms.optimizers import COBYLA, L_BFGS_B\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed, Tensor, nn\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    PoissonNLLLoss,\n",
    "    CrossEntropyLoss,\n",
    "    MaxPool2d,\n",
    "    AvgPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    "    ELU\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor, VQR\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "from qiskit_aer import AerSimulator\n",
    "aersim = AerSimulator()\n",
    "\n",
    "algorithm_globals.random_seed = 42\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "from cadena_ploscb.data import Dataset, MonkeySubDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\") if (torch.cuda.is_available() and DEVICE == \"gpu\") else torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "torch.cuda.set_per_process_memory_fraction(0.5)\n",
    "\n",
    "# torch.cuda.set_per_process_memory_fraction(0.5, 0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_step(x, a, b):\n",
    "    return torch.minimum(torch.tensor(b - a, dtype=torch.float32), \n",
    "      F.relu(x - torch.tensor(a, dtype=torch.float32))) / (b - a)\n",
    "\n",
    "def tent(x, a, b):\n",
    "    z = torch.tensor(0, dtype=torch.float32).to(device)\n",
    "    d = torch.tensor(2 * (b - a), dtype=torch.float32).to(device)\n",
    "    a = torch.tensor(a, dtype=torch.float32).to(device)\n",
    "    return torch.min(torch.max(x - a, z), torch.max(a + d - x, z)) / (b - a)\n",
    "\n",
    "#Function used to map the Model output to neuron firing rates\n",
    "def output_nonlinearity(x, vmin=-3.0, vmax=6.0, num_bins=10):\n",
    "    elu = torch.nn.functional.elu(x - 1.0).to(device) + 1.0\n",
    "    _, neurons = x.shape\n",
    "\n",
    "    k = int(num_bins / 2)\n",
    "    num_bins = 2 * k\n",
    "    bins = np.linspace(vmin, vmax, num_bins + 1, endpoint=True)\n",
    "    segments = [tent(x, a, b) for a, b in zip(bins[:-2], bins[1:-1])] + [lin_step(x, bins[-2], bins[-1])]\n",
    "\n",
    "    a = nn.Parameter(torch.zeros(neurons, num_bins, 1, \n",
    "      dtype=torch.float32)).to(device)\n",
    "    a_exp = torch.exp(a)\n",
    "    v = torch.cat([torch.reshape(s, (-1, neurons, 1)) for s in segments], dim=2).to(device).permute(1, 0, 2)\n",
    "    multiplier = torch.matmul(v, a_exp).view(neurons, -1).t()\n",
    "    return multiplier * elu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtracting mean: 112.51203\n"
     ]
    }
   ],
   "source": [
    "def inv_elu(x):\n",
    "    \"\"\"Inverse elu function.\"\"\"\n",
    "    y = x.copy()\n",
    "    idx = y < 1.0\n",
    "    y[idx] = np.log(y[idx]) + 1.0\n",
    "    return y\n",
    "    \n",
    "data_dict = Dataset.get_clean_data()\n",
    "dataset = MonkeySubDataset(data_dict, seed=1000, train_frac=0.8, subsample=2, crop=30)\n",
    "\n",
    "# b_out is calculated as inverse ELU of responses mean\n",
    "# Used as input for non-linear mapping the model output to neuron firing rates\n",
    "_, responses, _ = dataset.train()\n",
    "b_out = torch.tensor(inv_elu(responses.mean(axis=0))).to(device)\n",
    "b_out = b_out[NEURONS_FROM:NEURONS_FROM+QUBITS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hybrid torch NN module\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 32, kernel_size=13,padding='valid').to(device)\n",
    "        self.conv2 = Conv2d(32, 32, kernel_size=3,padding='same').to(device)\n",
    "        self.conv3 = Conv2d(32, 32, kernel_size=3,padding='same').to(device)\n",
    "        self.pool = AvgPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = Linear(32*28*28, 32*QUBITS)  # 32 * QUBIT-dimensional output\n",
    "        self.fc2 = Linear(32*QUBITS, QUBITS)  # QUBIT-dimensional output\n",
    "        # self.qnn = TorchConnector(qnn)  # Apply torch connector\n",
    "        # self.conv4 = Conv2d(1, QUBITS, (QUBITS, 1)).to(device)\n",
    "        init.trunc_normal_(self.conv1.weight, mean=0.0, std=0.01)\n",
    "        # W_spatial = torch.randn(QUBITS, 1).to(device) * 0.01\n",
    "        # W_spatial_flat = W_spatial.view(QUBITS, 1, 1, 1)\n",
    "        \n",
    "        # self.conv4.weight.data = self.conv4.weight.data + W_spatial_flat\n",
    "        self.W_features = nn.Parameter(torch.randn(1, NEURONS_PREDICTED).to(device) * 0.01)\n",
    "        self.elu = ELU()\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.elu(self.conv1(x))\n",
    "        x = self.elu(self.conv2(x))\n",
    "        x = self.elu(self.conv3(x))\n",
    "        print(\"X after conv 3\", x.shape)\n",
    "\n",
    "        # x = self.pool(x)\n",
    "        # print(\"X after pool\", x.shape)\n",
    "        # x = self.fc1(torch.flatten(x, start_dim=1))\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.elu(self.qnn(x))\n",
    "        sz = x.shape\n",
    "        px_x_conv = sz[2]\n",
    "        px_y_conv = sz[3]\n",
    "        px_conv = px_x_conv * px_y_conv\n",
    "        conv_flat = x.reshape(-1, 1, 32, px_conv).to(device)\n",
    "        print(\"conv_flat\", conv_flat.shape)\n",
    "\n",
    "        W_spatial = nn.Parameter(torch.nn.init.trunc_normal_(torch.empty(px_conv, NEURONS_PREDICTED), mean=0.0, std=0.01)).to(device)\n",
    "        print(\"W_Spatial\", W_spatial.shape)\n",
    "        W_spatial_flat = W_spatial.view(px_conv, 1, 1, NEURONS_PREDICTED).to(device)\n",
    "        print(\"W_spatial_flat\", W_spatial_flat.shape)\n",
    "        h_spatial = nn.functional.conv2d(conv_flat, W_spatial_flat, stride=1, padding=0).to(device)  # dot product\n",
    "        print(\"W_spatial\", W_spatial.shape, \"W_spatial_flat\", W_spatial_flat.shape, \"h_spatial\", h_spatial.shape, \"self.W_features\", self.W_features.shape)\n",
    "        h_out = torch.sum(h_spatial * self.W_features, dim=(1, 2)).to(device)\n",
    "        # conv_flat = x.reshape(-1, 1, px_conv, 1)\n",
    "        # h_spatial = self.elu(self.conv4(conv_flat)) #batch x 1 x 32 x neurons\n",
    "        # h_spatial = h_spatial.permute(0, 2, 3, 1)\n",
    "        # h_out = torch.sum(torch.mul(h_spatial, self.W_features), dim=(1, 2))\n",
    "        pred = output_nonlinearity(h_out + b_out, vmin=-3.0, vmax=6.0, num_bins=10)\n",
    "        return pred\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_uniform(low=0, high=1, base=10):\n",
    "    \"\"\"draw samples from a uniform distribution in logspace\"\"\"\n",
    "    return np.power(base, np.random.uniform(low, high))\n",
    "    \n",
    "\n",
    "def smoothness_regularizer_2d(W, weight=1.0):\n",
    "    # Define the Laplacian kernel\n",
    "    lap = torch.tensor([[0.25, 0.5, 0.25], [0.5, -3.0, 0.5], [0.25, 0.5, 0.25]]).unsqueeze(0).unsqueeze(0)\n",
    "    lap = lap.repeat(W.size(1), 1, 1, 1)  # Assuming W is in shape (out_channels, in_channels, H, W)\n",
    "    lap = lap.to(W.device)  # Ensure the kernel is on the same device as W\n",
    "\n",
    "    # Apply depthwise convolution using groups in Conv2d\n",
    "    out_channels, in_channels, _, _ = W.size()\n",
    "    W_lap = F.conv2d(W.permute(1, 0, 2, 3), lap, groups=in_channels, padding='same')\n",
    "\n",
    "    # Calculate penalty\n",
    "    penalty = torch.sum(W_lap ** 2, dim=[1, 2, 3]) / torch.sum(W ** 2, dim=[2, 3])\n",
    "    penalty = weight * torch.sum(penalty)\n",
    "\n",
    "    return penalty\n",
    "\n",
    "def group_sparsity_regularizer_2d(W, weight=1.0):\n",
    "    # Calculate the sum of squares of W, then sum over the 0th and 1st dimension (assuming W is in shape of [C, H, W] or [C, H, W, D])\n",
    "    sum_of_squares = torch.sum(W ** 2, dim=[0, 1])\n",
    "    \n",
    "    # Calculate the square root of the sum of squares, then sum over all remaining dimensions\n",
    "    sqrt_sum_of_squares = torch.sqrt(sum_of_squares)\n",
    "    penalty = torch.sum(sqrt_sum_of_squares)\n",
    "    \n",
    "    # Multiply by the weight and return\n",
    "    penalty = weight * penalty\n",
    "\n",
    "    return penalty\n",
    "\n",
    "def smoothness_regularizer_1d(w, weight=1.0, order=2):\n",
    "    penalty = 0\n",
    "    # Define the kernel for 1D convolution\n",
    "    kernel = torch.tensor([-1.0, 1.0], dtype=torch.float32).reshape(1, 1, 2).to(w.device)\n",
    "\n",
    "    for _ in range(order):\n",
    "        # Apply 1D convolution\n",
    "        w = F.conv1d(w, kernel, stride=1, padding='valid')\n",
    "        # Calculate and accumulate penalty\n",
    "        penalty += torch.sum(torch.mean(w ** 2, dim=1))\n",
    "    \n",
    "    # Apply weight to the penalty\n",
    "    penalty = weight * penalty\n",
    "\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT = True\n",
    "# BATCH_SIZE = 256\n",
    "# if(PLOT):\n",
    "#   rows = 10\n",
    "#   fig, axes = plt.subplots(nrows=rows, ncols=rows, sharex=True, figsize=(20, 20))\n",
    "#   img_batch, res_batch, real_batch = dataset.minibatch(BATCH_SIZE)\n",
    "#   print(\"img_batch\", img_batch.shape)\n",
    "#   images = torch.tensor(img_batch).permute(0, 3, 1, 2)\n",
    "#   print(\"images\", images.shape)\n",
    "#   print(\"squeezed\", images[0].squeeze().shape)\n",
    "#   for p in range(rows * rows):\n",
    "#     axes[p//rows,p%rows].imshow(images[p].squeeze(), cmap=\"gray\")\n",
    "#     axes[p//rows,p%rows].set_xticks([])\n",
    "#     axes[p//rows,p%rows].set_yticks([])\n",
    "\n",
    "#   fig, axes = plt.subplots(nrows=rows, ncols=rows, sharex=True, figsize=(30, 30))\n",
    "#   for p in range(rows * rows):\n",
    "#     axes[p//rows,p%rows].imshow(img_batch[p].squeeze(), cmap=\"gray\")\n",
    "#     axes[p//rows,p%rows].set_xticks([])\n",
    "#     axes[p//rows,p%rows].set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from torchmetrics.regression import PearsonCorrCoef\n",
    "\n",
    "def evaluate_corr_vals(pred, res, real_res):\n",
    "  corrs = []\n",
    "  for i in range(NUM_NEURONS):\n",
    "    # keep only entries corresponding to real_res\n",
    "    r = res[:, i]\n",
    "    p = pred[:, i]\n",
    "    b = real_res[:, i].astype(bool)\n",
    "    r = np.compress(b, r)\n",
    "    p = np.compress(b, p)\n",
    "    corr = stats.pearsonr(r, p)[0]\n",
    "    if np.isnan(corr):\n",
    "        print(\"INFO: corr for neuron \" + str(i) + \" is nan - replaced by 0\")\n",
    "        corr = 0\n",
    "    corrs.append(corr)\n",
    "\n",
    "  return corrs\n",
    "\n",
    "def evaluate_avg_corr_val(pred, res, real_res):\n",
    "  \"\"\"Prediction correlation averaged across neurons on validation set.\"\"\"\n",
    "  avg_corr = np.mean(evaluate_corr_vals(pred, res, real_res))\n",
    "  return avg_corr\n",
    "\n",
    "def evaluate_pearson_correl(pred, res, real_res):\n",
    "  pearson = PearsonCorrCoef(num_outputs=pred.shape[1]).to(device)\n",
    "  eff_res = res * real_res\n",
    "  return torch.mean(pearson(pred, eff_res))\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CustomLoss, self).__init__()\n",
    "\n",
    "  def forward(self, prediction, responses_pair):\n",
    "    response, real_responses = responses_pair\n",
    "    # Calculate the loss\n",
    "    loss = torch.mean(\n",
    "        torch.sum((prediction - response * torch.log(prediction + 1e-9)) * real_responses, dim=0)\n",
    "        / torch.sum(real_responses, dim=0)\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtracting mean: 112.51203\n",
      "18560\n",
      "X after conv 3 torch.Size([256, 32, 28, 28])\n",
      "conv_flat torch.Size([256, 1, 32, 784])\n",
      "W_Spatial torch.Size([784, 166])\n",
      "W_spatial_flat torch.Size([784, 1, 1, 166])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loss_list = []  # Store loss history\n",
    "\n",
    "def train():\n",
    "  data_dict = Dataset.get_clean_data()\n",
    "  dataset = MonkeySubDataset(data_dict, seed=1000, train_frac=0.8, subsample=2, crop=30)\n",
    "\n",
    "  smooth_weights = torch.tensor([log_uniform(low=-9, high=-3.5), 0, 0]).to(device)\n",
    "  sparse_weights = [0.0, 0.00025, 0.00025]\n",
    "  readout_sparse_weight = log_uniform(low=-5.5, high=-1)\n",
    "  trainSize = dataset.train()\n",
    "  print(trainSize[0].shape[0])\n",
    "\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "  loss_func = nn.CrossEntropyLoss()\n",
    "  num_neurons= 166 #int(QUBITS/2)\n",
    "\n",
    "  # Start training\n",
    "  epochs = EPOCHS  # Set number of epochs\n",
    "  model.train()  # Set model to training mode\n",
    "\n",
    "  log_interval = 10\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "\n",
    "    not_improved = 0\n",
    "    num_lr_updates = 0\n",
    "    dataset.next_epoch()\n",
    "\n",
    "    for p in range(500):\n",
    "      if(BATCH_SIZE*(p+1) > trainSize[0].shape[0]):\n",
    "        # for name, param in model.named_parameters():\n",
    "        #   if param.requires_grad and \"weight\" in name:\n",
    "        #     print(name, param.data.shape, param.data[0, 0, 0, :3].data)    \n",
    "        imgs_val, res_val, real_resp_val = dataset.val()\n",
    "        data_val = torch.Tensor(imgs_val).to(device)\n",
    "        target_val = torch.Tensor(res_val).to(device)\n",
    "        real_target_val = torch.Tensor(real_resp_val).to(device)\n",
    "        target_val = target_val[:,NEURONS_FROM:NEURONS_FROM+QUBITS]\n",
    "        real_target_val = real_target_val[:,NEURONS_FROM:NEURONS_FROM+QUBITS]\n",
    "        output_val = model(data_val)\n",
    "        loss = loss_func(output_val, target_val)\n",
    "        # pearson = evaluate_pearson_correl(output_val, target_val, real_target_val)\n",
    "        print(epoch, \"step \", p, \"Loss \", loss.item())\n",
    "        break\n",
    "      imgs_batch, res_batch, real_batch = dataset.minibatch(BATCH_SIZE)\n",
    "      data = torch.Tensor(imgs_batch).to(device)\n",
    "      target = torch.Tensor(res_batch).to(device)\n",
    "      target = target[:,NEURONS_FROM:NEURONS_FROM+QUBITS]\n",
    "      real_target = torch.Tensor(real_batch).to(device)\n",
    "      output = model(data)\n",
    "      # print(output[0].data, target[0].data)\n",
    "      # print(p, \"output\", output.data)\n",
    "      loss = loss_func(output, target)  # Calculate loss\n",
    "      penalty1 = 0.0\n",
    "      penalty2 = 0.0\n",
    "      penalty3 = 0.0\n",
    "      for name, param in model.named_parameters():\n",
    "        if 'conv1.weight' in name:  # Assuming you want to regularize weights\n",
    "          penalty1 = smoothness_regularizer_2d(torch.permute(param, (2, 3, 0, 1)), smooth_weights[0]) + group_sparsity_regularizer_2d(param, sparse_weights[0])\n",
    "        # elif 'conv2.weight' in name:  # Assuming you want to regularize weights\n",
    "        #   penalty2 = smoothness_regularizer_2d(torch.permute(param, (2, 3, 0, 1)), smooth_weights[1]) + group_sparsity_regularizer_2d(param, sparse_weights[1])\n",
    "        # elif 'conv3.weight' in name:  # Assuming you want to regularize weights\n",
    "        #   penalty3 = smoothness_regularizer_2d(torch.permute(param, (2, 3, 0, 1)), smooth_weights[2]) + group_sparsity_regularizer_2d(param, sparse_weights[2])\n",
    "      # for name, param in model.named_parameters():\n",
    "      #   if param.requires_grad and name == 'qnn.weight':\n",
    "      #     print(name, param.data)      \n",
    "      loss += penalty1 + penalty2 + penalty3\n",
    "      print(epoch, p, \"Loss \", loss.item(), \"MSE\", torch.mean((target - output) ** 2).item() # output.T[:, :5].data, target.T[:, :5].data, \n",
    "      )\n",
    "      pearson = evaluate_pearson_correl(output, target, real_target[:,NEURONS_FROM:NEURONS_FROM+NEURONS_PREDICTED])\n",
    "      optimizer.zero_grad()  # Initialize gradient set_to_none=True\n",
    "      loss.backward()  # Backward pass\n",
    "      optimizer.step()  # Optimize weights\n",
    "      total_loss.append(loss.item())  # Store loss\n",
    "      loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    # print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))\n",
    "\n",
    "if(MODE == \"Train\"):\n",
    "  train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(MODE == \"Train\"):\n",
    "  plt.plot(loss_list)\n",
    "  plt.title(\"Hybrid QNN Training Convergence\")\n",
    "  plt.xlabel(\"Training Iterations\")\n",
    "  plt.ylabel(\"Poisson NLL Loss\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate, calculate FEV\n",
    "images_test, responses_test, real_responses_test = dataset.test()\n",
    "print(\"images_test\", images_test.shape, \"responses_test\", responses_test.shape, \"real_responses_test\", real_responses_test.shape)\n",
    "# print(\"real_respones\", real_responses_test[0, 0:10, 0:4])\n",
    "# print(\"respones\", responses_test[0, 0:10, 0:4])\n",
    "total_count = images_test.shape[0]\n",
    "print(\"total_count\", total_count)\n",
    "iterations = total_count//BATCH_SIZE +1\n",
    "nrep, nim, tneu = responses_test.shape\n",
    "nneu = QUBITS\n",
    "fneu = NEURONS_FROM\n",
    "\n",
    "predictions = torch.zeros(1, 166)\n",
    "\n",
    "for i in range(iterations):\n",
    "  data = torch.Tensor(images_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE]).to(device)\n",
    "  predictions_test = model(data)\n",
    "  if i == 0:\n",
    "    predictions = predictions_test\n",
    "  else:\n",
    "    predictions = torch.cat((predictions, predictions_test))\n",
    "# print(\"predictions\", predictions[0:5, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanarray(real_resps, resps):\n",
    "  \"\"\"Inserts nan at every position in resps where corresponding positions in real_resps are 0.\n",
    "  Hence, leading to an array of resps where non-real responses have value nan.\n",
    "  \"\"\"\n",
    "\n",
    "  return np.where(real_resps, resps, np.nan)\n",
    "\n",
    "  #Calculate Fraction of Explainable Variance\n",
    "def calculateFEV3(predictions_test, responses_test, real_responses_test, \n",
    "  nrep, nim, tneu, nneu, fneu):\n",
    "  predictions_test = torch.tile(predictions_test, (4, 1)).detach().cpu().numpy()\n",
    "  resps_test_nan = dataset.nanarray(real_responses_test, responses_test)\n",
    "  resps_test = resps_test_nan.reshape([nrep * nim, tneu])\n",
    "  sresps_test = resps_test[:,fneu:fneu+nneu]\n",
    "  print(\"sresps_test\", sresps_test.shape, \"predictions_test\", predictions_test.shape)\n",
    "  MSE = np.nanmean((predictions_test - sresps_test) ** 2, axis=0)\n",
    "  print(\"MSE\", MSE)\n",
    "  obs_var_avg, total_variance, explainable_var = [], [], []\n",
    "  for n in range(tneu):\n",
    "    if(n < NEURONS_FROM or n >= NEURONS_FROM + QUBITS):\n",
    "      continue\n",
    "    print(\"processing for neuron\", n)\n",
    "    rep = dataset.repetitions[n]\n",
    "    resp_ = resps_test_nan[:rep, :, n]\n",
    "    print(\"resp_\", resp_.shape, resp_[:, 0:4])\n",
    "    v = np.nanvar(resp_, axis=0, ddof=1)\n",
    "    print(\"v\", v.shape, v[0:4])\n",
    "    obs_var = np.nanmean(v, axis=0)\n",
    "    print(\"obs_var\", obs_var)\n",
    "    obs_var_avg.append(obs_var)\n",
    "    tot_var = np.nanvar(resp_, axis=(0, 1), ddof=1)\n",
    "    print(\"tot_var\", tot_var)\n",
    "    total_variance.append(tot_var)\n",
    "    explainable_var.append(tot_var - obs_var)\n",
    "  total_variance = np.array(total_variance)\n",
    "  explainable_var = np.array(explainable_var)\n",
    "  var_explained = total_variance - MSE\n",
    "  print(\n",
    "    \"indices\", np.nonzero(MSE < total_variance),\n",
    "    \"MSE\", MSE[MSE < total_variance], \n",
    "    \"total_variance\", total_variance[MSE < total_variance], \n",
    "    \"var_explained\", var_explained[MSE < total_variance], \n",
    "    \"explainable_var\", explainable_var[MSE < total_variance], \n",
    "    \"fev%\", (var_explained * 100 / explainable_var)[MSE < total_variance])\n",
    "  return var_explained / explainable_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fev = calculateFEV3(predictions, responses_test, real_responses_test, nrep, nim, tneu, nneu, fneu)\n",
    "print(\"FEV\", fev[fev > 0]*100, fev[fev > 0].mean() * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".canonical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
